{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 4 - Question 5: Mean shift Tracking"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Performance Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(boxA, boxB):\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "\n",
    "    # compute the IoU by taking the intersection area and dividing\n",
    "    # it by the sum of prediction + ground-truth areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "\n",
    "    # return the IoU value\n",
    "    return iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"./KylianMbappe.mp4\") # video\n",
    "\n",
    "# capture one frame\n",
    "ret,frame = cap.read()\n",
    "\n",
    "# detect a face on the first frame\n",
    "face_detector = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "face_boxes = face_detector.detectMultiScale(frame)\n",
    "\n",
    "if len(face_boxes)==0:\n",
    "    print('no face detected')\n",
    "    assert(False)\n",
    "\n",
    "# initialize the tracing window around the (first) detected face\n",
    "(x,y,w,h) = tuple(face_boxes[0]) \n",
    "track_window = (x,y,w,h)\n",
    "\n",
    "## region of interest for tracking\n",
    "roi = frame[y:y+h, x:x+w]\n",
    "\n",
    "# convert the roi to HSV so we can construct a histogram of Hue \n",
    "hsv_roi =  cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# why do we need this mask? (remember the cone?)\n",
    "# read the description for Figure 3 in the original Cam Shift paper: http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.14.7673 \n",
    "mask = cv2.inRange(hsv_roi, np.array((0., 60.,32.)), np.array((180.,255.,255.)))\n",
    "\n",
    "# form histogram of hue in the roi\n",
    "roi_hist = cv2.calcHist([hsv_roi],[0],mask,[180],[0,180])\n",
    "\n",
    "# normalize the histogram array values so they are in the min=0 to max=255 range\n",
    "cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
    "\n",
    "# termination criteria for mean shift: 10 iteration or shift less than 1 pixel\n",
    "term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n",
    "\n",
    "\n",
    "ious = []\n",
    "frames = []\n",
    "lower_iou_frames = []\n",
    "count = 0\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # grab a frame\n",
    "    ret ,frame = cap.read() \n",
    "    \n",
    "    if ret == True: \n",
    "  \n",
    "        # convert to HSV\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # histogram back projection using roi_hist \n",
    "        dst = cv2.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
    "        \n",
    "        # use meanshift to shift the tracking window\n",
    "        ret, track_window = cv2.meanShift(dst, track_window, term_crit)\n",
    "        \n",
    "        # display tracked window\n",
    "        x,y,w,h = track_window\n",
    "        img = cv2.rectangle(frame, (x,y), (x+w,y+h), (0,0,255),5)\n",
    "        \n",
    "        # detector\n",
    "        face_boxes = face_detector.detectMultiScale(frame)\n",
    "        if len(face_boxes) == 0:\n",
    "            iou = 0\n",
    "        else:\n",
    "            x2,y2,w2,h2 = 0, 0, 0, 0\n",
    "            max_iou = -1\n",
    "            for face_box in face_boxes:\n",
    "                tx2,ty2,tw2,th2 = face_box\n",
    "                iou = calculate_iou([x,y, x+w,y+h], [tx2,ty2,tx2+tw2,ty2+th2])\n",
    "                \n",
    "                if iou > max_iou:\n",
    "                    max_iou = iou\n",
    "                    x2,y2,w2,h2 = tx2,ty2,tw2,th2\n",
    "            iou = max_iou\n",
    "            img2 = cv2.rectangle(frame, (x2,y2), (x2+w2,y2+h2), (0,255,0),5)\n",
    "        \n",
    "        frames.append(frame)\n",
    "        ious.append(iou)\n",
    "        if iou < 0.5 and iou != 0:\n",
    "            lower_iou_frames.append(frame)\n",
    "        \n",
    "        cv2.imshow('mean shift tracking demo',img)\n",
    "        \n",
    "        if cv2.waitKey(33) & 0xFF == 27: # wait a bit and exit is ESC is pressed\n",
    "            break\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_count = [i for i in range(2, len(ious)+1)]\n",
    "plt.plot(frame_count, ious[1:])\n",
    "plt.xlabel(\"Frame #\")\n",
    "plt.ylabel(\"IoU\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the highest/lowest smaple frame\n",
    "min_iou_index = ious.index(min(ious))\n",
    "max_iou_index = ious.index(max(ious))\n",
    "\n",
    "lowest_frame = frames[min_iou_index]\n",
    "highest_frame = frames[max_iou_index]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 13))\n",
    "axes[0].imshow(cv2.cvtColor(highest_frame, cv2.COLOR_BGR2RGB))\n",
    "axes[1].imshow(cv2.cvtColor(lowest_frame, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title(f'Highest IoU Sample {ious[max_iou_index]}')\n",
    "axes[1].set_title(f'Lowest IoU Sample {ious[min_iou_index]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IoU > 50%\n",
    "ious_arr = np.array(ious)\n",
    "iou_50 = len(np.where(ious_arr > 0.5)[0])/len(ious_arr)\n",
    "\n",
    "print(f'{iou_50*100}% of frames have IoU larger than 50%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the histogram, we notice only 1 IoU is lower than 10%, which is 0% indeed. To analyse the lower IoUs, we will pick those smaller than 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some frames with IoU < 50%\n",
    "print(f'There are {len(lower_iou_frames)} frames that has 0% < accurcy < 50%')\n",
    "fig, axes = plt.subplots(2, 2, figsize=(13, 10))\n",
    "fig.suptitle('4 frames with IoU < 50%',y=0.87, fontsize=12)\n",
    "axes[0,0].imshow(cv2.cvtColor(lower_iou_frames[0], cv2.COLOR_BGR2RGB))\n",
    "axes[0,1].imshow(cv2.cvtColor(lower_iou_frames[1], cv2.COLOR_BGR2RGB))\n",
    "axes[1,0].imshow(cv2.cvtColor(lower_iou_frames[2], cv2.COLOR_BGR2RGB))\n",
    "axes[1,1].imshow(cv2.cvtColor(lower_iou_frames[3], cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comment:\n",
    "- Red box: mean shift tracked box. Green box: Viola-Jones detected box\n",
    "- Comparing the four pairs of boxes, we can see green box of Viola-Jones detection is more accurate in facial detection. \n",
    "- Viola-Jones is a trained machine learning approach to detect faces, while mean shift tracking relies on appearance and motion cues to track objects (we used hue histogram here). Therefore, mean shift tracking is more sensitive to variations in environment. For example, in the video Mbappe touched his nose."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Implement A Simple Variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"./KylianMbappe.mp4\") # video\n",
    "\n",
    "# capture one frame\n",
    "ret,frame = cap.read()\n",
    "\n",
    "# detect a face on the first frame\n",
    "face_detector = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "face_boxes = face_detector.detectMultiScale(frame)\n",
    "\n",
    "if len(face_boxes)==0:\n",
    "    print('no face detected')\n",
    "    assert(False)\n",
    "\n",
    "# initialize the tracing window around the (first) detected face\n",
    "(x,y,w,h) = tuple(face_boxes[0]) \n",
    "track_window = (x,y,w,h)\n",
    "\n",
    "## region of interest for tracking\n",
    "roi = frame[y:y+h, x:x+w]\n",
    "\n",
    "# gray_roi: mag, angle\n",
    "gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "gray_roi = cv2.GaussianBlur(gray_roi, (5, 5), 1) # gaussian blur\n",
    "Ix = cv2.Sobel(gray_roi, cv2.CV_32F, 1, 0, ksize=5)\n",
    "Iy = cv2.Sobel(gray_roi, cv2.CV_32F, 0, 1, ksize=5)\n",
    "\n",
    "magnitude = np.zeros_like(Ix)\n",
    "angle = np.zeros_like(Ix, dtype='uint8')  # range 0-360 degrees\n",
    "cv2.cartToPolar(Ix, Iy, magnitude, angle, angleInDegrees=True)\n",
    "\n",
    "mask = cv2.inRange(magnitude, np.max(magnitude) * .1, np.inf)\n",
    "\n",
    "# mag, angle = cv2.cartToPolar(Ix, Iy, angleInDegrees=True)\n",
    "# angle = np.array([angle], dtype=np.uint16)\n",
    "\n",
    "# mask = cv2.inRange(mag, np.max(mag) / 20.0, float(np.max(mag)))\n",
    "\n",
    "# form histogram of hue in the roi\n",
    "roi_hist = cv2.calcHist([angle],[0],mask,[24],[0,360])\n",
    "\n",
    "# normalize the histogram array values so they are in the min=0 to max=255 range\n",
    "cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
    "\n",
    "# termination criteria for mean shift: 10 iteration or shift less than 1 pixel\n",
    "term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n",
    "\n",
    "ious = []\n",
    "frames = []\n",
    "lower_ious = []\n",
    "lower_iou_frames = []\n",
    "count = 0\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # grab a frame\n",
    "    ret ,frame = cap.read() \n",
    "    \n",
    "    if ret == True: \n",
    "  \n",
    "        # convert to HSV\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # histogram back projection using roi_hist \n",
    "        dst = cv2.calcBackProject([hsv],[0],roi_hist,[0,360],1)\n",
    "        \n",
    "        # use meanshift to shift the tracking window\n",
    "        ret, track_window = cv2.meanShift(dst, track_window, term_crit)\n",
    "        \n",
    "        # display tracked window\n",
    "        x,y,w,h = track_window\n",
    "        img = cv2.rectangle(frame, (x,y), (x+w,y+h), (0,0,255),5)\n",
    "        \n",
    "        # detector\n",
    "        face_boxes = face_detector.detectMultiScale(frame)\n",
    "        if len(face_boxes) == 0:\n",
    "            iou = 0\n",
    "        else:\n",
    "            x2,y2,w2,h2 = 0, 0, 0, 0\n",
    "            max_iou = -1\n",
    "            for face_box in face_boxes:\n",
    "                tx2,ty2,tw2,th2 = face_box\n",
    "                iou = calculate_iou([x,y, x+w,y+h], [tx2,ty2,tx2+tw2,ty2+th2])\n",
    "                \n",
    "                if iou > max_iou:\n",
    "                    max_iou = iou\n",
    "                    x2,y2,w2,h2 = tx2,ty2,tw2,th2\n",
    "            iou = max_iou\n",
    "            img2 = cv2.rectangle(frame, (x2,y2), (x2+w2,y2+h2), (0,255,0),5)\n",
    "        \n",
    "        frames.append(frame)\n",
    "        ious.append(iou)\n",
    "        if iou < 0.5 and iou != 0:\n",
    "            lower_iou_frames.append(frame)\n",
    "            lower_ious.append(iou)\n",
    "        \n",
    "        cv2.imshow('mean shift tracking demo',img)\n",
    "        \n",
    "        if cv2.waitKey(33) & 0xFF == 27: # wait a bit and exit is ESC is pressed\n",
    "            break\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_count = [i for i in range(2, len(ious)+1)]\n",
    "plt.plot(frame_count, ious[1:])\n",
    "plt.xlabel(\"Frame #\")\n",
    "plt.ylabel(\"IoU\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IoU > 70%\n",
    "ious_arr = np.array(ious)\n",
    "iou_higher_70 = len(np.where(ious_arr > 0.7)[0])/len(ious_arr)\n",
    "\n",
    "print(f'{iou_higher_70*100}% of frames have IoU larger than 70%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IoU < 50%\n",
    "ious_arr = np.array(ious)\n",
    "iou_less_50 = len(np.where(ious_arr < 0.5)[0])/len(ious_arr)\n",
    "iou_larger_50 = 1-iou_less_50\n",
    "\n",
    "print(f'{iou_less_50*100}% of frames have IoU smaller than 50%')\n",
    "print(f'{iou_larger_50*100}% of frames have IoU larger than 50%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the high/low smaple frames\n",
    "max_iou_index = ious.index(max(ious))\n",
    "highest_frame = frames[max_iou_index]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 13))\n",
    "axes[0].imshow(cv2.cvtColor(highest_frame, cv2.COLOR_BGR2RGB))\n",
    "axes[1].imshow(cv2.cvtColor(lower_iou_frames[0], cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title(f'High IoU Sample {ious[max_iou_index]}')\n",
    "axes[1].set_title(f'Low IoU Sample {lower_ious[0]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
